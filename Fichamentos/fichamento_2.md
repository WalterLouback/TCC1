# An Empirical Evaluation of GitHub Copilot's Code Suggestions

Nhan Nguyen; Sarah Nadi. "An Empirical Evaluation of GitHub Copilot's Code Suggestions," 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR), 2022. doi: 10.1109/MSR52599.2022.00014

## 1. Fichamento de Conteúdo

Este artigo apresenta um estudo empírico sobre a avaliação das sugestões de código do GitHub Copilot, uma ferramenta de "programador de par de IA" lançada pelo GitHub e OpenAI. O estudo utiliza 33 questões do LeetCode para criar consultas para o Copilot em quatro linguagens de programação diferentes. A correção das 132 soluções geradas pelo Copilot é avaliada executando os testes fornecidos pelo LeetCode, e a compreensibilidade é avaliada usando as métricas de complexidade ciclomática e complexidade cognitiva do SonarQube. Os resultados mostram que as sugestões de Java do Copilot têm a maior pontuação de correção (57%), enquanto JavaScript é a mais baixa (27%). No geral, as sugestões do Copilot apresentam baixa complexidade, sem diferenças notáveis entre as linguagens de programação. O estudo também identifica algumas deficiências potenciais do Copilot, como a geração de código que pode ser simplificado e código que depende de métodos auxiliares não definidos.

## 2. Fichamento Bibliográfico 

**Título:** An Empirical Evaluation of GitHub Copilot's Code Suggestions

**Autores:** Nhan Nguyen, Sarah Nadi

**Publicação:** 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR), 2022

**Ano:** 2022

**DOI:** 10.1109/MSR52599.2022.00014

**URL:** https://ieeexplore.ieee.org/document/9796235/

**Tipo de Estudo:** Empírico

**Área:** Engenharia de Software

**Palavras-chave:** GitHub Copilot, Geração de Código, Sugestões de Código, Qualidade de Código, Estudo Empírico, LeetCode.

## 3. Fichamento de Citações 

